{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before running, you have to set the parameters at these numbers: 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize progress bars\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a github access token to perform a large number of requests (rate limit)\n",
    "with open(\"config.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "token = cfg['access_token']\n",
    "headers = {'Authorization': 'token ' + token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, change comments where needed\n",
    "\n",
    "# for ETHZ Germany:\n",
    "# repo_name = 'covid-19-Re/dailyRe-Data'\n",
    "# branch = 'master'\n",
    "# file_path = 'DEU-estimates.csv'\n",
    "\n",
    "# for ETHZ Austria:\n",
    "# repo_name = 'covid-19-Re/dailyRe-Data'\n",
    "# branch = 'master'\n",
    "# file_path = 'AUT-estimates.csv'\n",
    "\n",
    "# for ETHZ Switzerland:\n",
    "# repo_name = 'covid-19-Re/dailyRe-Data'\n",
    "# branch = 'master'\n",
    "# file_path = 'CHE-estimates.csv'\n",
    "\n",
    "# for TU Ilmenau Germany\n",
    "# repo_name = 'Stochastik-TU-Ilmenau/COVID-19'\n",
    "# branch = 'gh-pages'\n",
    "# file_path = 'data/estimates/Germany_RKI_R.csv'\n",
    "\n",
    "# for TU Ilmenau Austria\n",
    "# repo_name = 'Stochastik-TU-Ilmenau/COVID-19'\n",
    "# branch = 'gh-pages'\n",
    "# file_path = 'data/estimates/Austria_JHU_R.csv'\n",
    "\n",
    "# for TU Ilmenau Switzerland\n",
    "# repo_name = 'Stochastik-TU-Ilmenau/COVID-19'\n",
    "# branch = 'gh-pages'\n",
    "# file_path = 'data/estimates/Switzerland_JHU_R.csv'\n",
    "\n",
    "# for OWID:\n",
    "# repo_name = 'owid/covid-19-data'\n",
    "# branch = 'master'\n",
    "# file_path = 'public/data/owid-covid-data.csv'\n",
    "# Note that OWID reports reproduction_rate only since 2020-11-13, this script will also download older data. This older data has to be removed from the data-raw folder before running the \"process_historic_data_owid.r\" script.\n",
    "\n",
    "# for globalrt:\n",
    "# repo_name = 'crondonm/TrackingR'\n",
    "# branch = 'main'\n",
    "# file_path = 'Estimates-Database/database.csv'\n",
    "\n",
    "# for epiforecast:\n",
    "# repo_name = 'epiforecasts/covid-rt-estimates'\n",
    "# branch = 'master'\n",
    "# file_path = 'national/cases/summary/rt.csv'\n",
    "\n",
    "# for zidatalab:\n",
    "repo_name = 'zidatalab/covid19dashboard'\n",
    "branch = 'master'\n",
    "file_path = 'data/plotdata/rwert_bund.json'\n",
    "\n",
    "# for RKI:\n",
    "# repo_name = 'robert-koch-institut/SARS-CoV-2-Nowcasting_und_-R-Schaetzung'\n",
    "# branch = 'main'\n",
    "# file_path = 'Nowcast_R_aktuell.csv'\n",
    "\n",
    "# for Swiss Data Science Center (SDSC): download files manually from gitlab repo: https://renkulab.io/gitlab/covid-19/covid-19-forecast/-/tree/master/data/JHU/prediction\n",
    "# try to download only predicition folder since repo is very large: https://bytenota.com/git-how-to-clone-a-specific-directory-from-a-git-repository/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get commit history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve information about all commits that modified the file we want\n",
    "all_commits = []\n",
    "\n",
    "page = 0\n",
    "while True:\n",
    "    page += 1\n",
    "    r = requests.get('https://api.github.com/repos/{}/commits'.format(repo_name),\n",
    "                     params = {'sha': branch, 'path': file_path, 'page': str(page)},\n",
    "                     headers=headers)\n",
    "\n",
    "    if (not r.ok) or (r.text == '[]'): break\n",
    "\n",
    "    all_commits += json.loads(r.text or r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sha of each commit\n",
    "all_shas = [c['sha'] for c in all_commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of each commit\n",
    "commit_dates = [pd.to_datetime(c['commit']['author']['date']) for c in all_commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframe\n",
    "df = pd.DataFrame({'sha': all_shas, 'commit_date': commit_dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date without time\n",
    "df['date'] = df.commit_date.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider last commit made each day\n",
    "df = df.loc[df.groupby('date')['commit_date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0b4ddcccfa9d12a382ef49cc8db8ee00206f40db</td>\n",
       "      <td>2020-11-17 16:08:09+00:00</td>\n",
       "      <td>2020-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>cd0befa33789f07f3a3ec24c6ae498c29ccbead1</td>\n",
       "      <td>2020-11-18 09:18:33+00:00</td>\n",
       "      <td>2020-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>e99943e4569be67f132903ddfb21cc35993bd0f1</td>\n",
       "      <td>2020-11-19 09:00:54+00:00</td>\n",
       "      <td>2020-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>842bc846112169bc4b705acf094506f48dd6f3b2</td>\n",
       "      <td>2020-11-20 15:18:25+00:00</td>\n",
       "      <td>2020-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3cf1c2104248f295160f5b71496b1ce90f2f4032</td>\n",
       "      <td>2020-11-21 06:06:58+00:00</td>\n",
       "      <td>2020-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e99494fc123b1c648924531caacd2bf2c9ea6c76</td>\n",
       "      <td>2022-01-27 03:47:47+00:00</td>\n",
       "      <td>2022-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5c0c262bfe1f63e2a5c1756baaa22070a665ffd</td>\n",
       "      <td>2022-01-28 03:45:55+00:00</td>\n",
       "      <td>2022-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b19e98fddf3e03af4addc79a854d4f352075c3b2</td>\n",
       "      <td>2022-01-29 04:47:11+00:00</td>\n",
       "      <td>2022-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fb7476f54374be7787bbc4dedc6b09fe0eeb6c90</td>\n",
       "      <td>2022-01-30 03:51:48+00:00</td>\n",
       "      <td>2022-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c09d30cdcd479174b699d36166be9549af3a7275</td>\n",
       "      <td>2022-01-31 03:53:43+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sha               commit_date  \\\n",
       "434  0b4ddcccfa9d12a382ef49cc8db8ee00206f40db 2020-11-17 16:08:09+00:00   \n",
       "433  cd0befa33789f07f3a3ec24c6ae498c29ccbead1 2020-11-18 09:18:33+00:00   \n",
       "432  e99943e4569be67f132903ddfb21cc35993bd0f1 2020-11-19 09:00:54+00:00   \n",
       "431  842bc846112169bc4b705acf094506f48dd6f3b2 2020-11-20 15:18:25+00:00   \n",
       "430  3cf1c2104248f295160f5b71496b1ce90f2f4032 2020-11-21 06:06:58+00:00   \n",
       "..                                        ...                       ...   \n",
       "4    e99494fc123b1c648924531caacd2bf2c9ea6c76 2022-01-27 03:47:47+00:00   \n",
       "3    e5c0c262bfe1f63e2a5c1756baaa22070a665ffd 2022-01-28 03:45:55+00:00   \n",
       "2    b19e98fddf3e03af4addc79a854d4f352075c3b2 2022-01-29 04:47:11+00:00   \n",
       "1    fb7476f54374be7787bbc4dedc6b09fe0eeb6c90 2022-01-30 03:51:48+00:00   \n",
       "0    c09d30cdcd479174b699d36166be9549af3a7275 2022-01-31 03:53:43+00:00   \n",
       "\n",
       "           date  \n",
       "434  2020-11-17  \n",
       "433  2020-11-18  \n",
       "432  2020-11-19  \n",
       "431  2020-11-20  \n",
       "430  2020-11-21  \n",
       "..          ...  \n",
       "4    2022-01-27  \n",
       "3    2022-01-28  \n",
       "2    2022-01-29  \n",
       "1    2022-01-30  \n",
       "0    2022-01-31  \n",
       "\n",
       "[426 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [03:36<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate over the rows of df and download the corresponding file\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):  \n",
    "    # try:      # try-except added only for globalrt because HTTP-Error occurred\n",
    "    #     df_temp = pd.read_csv('https://raw.githubusercontent.com/{}/{}/{}'.format(repo_name, row['sha'], file_path),\n",
    "    #                       low_memory=False)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # for zidatalab only:\n",
    "    df_temp = pd.read_json('https://raw.githubusercontent.com/{}/{}/{}'.format(repo_name, row['sha'], file_path))\n",
    "#2\n",
    "    # result_path =  '../data-raw/ETHZ DEU/' + str(row['date']) + '_ethz_deu_raw.csv'\n",
    "    # result_path =  '../data-raw/ETHZ AUT/' + str(row['date']) + '_ethz_aut_raw.csv'\n",
    "    # result_path =  '../data-raw/ETHZ CHE/' + str(row['date']) + '_ethz_che_raw.csv'\n",
    "    # result_path =  '../data-raw/Ilmenau DEU/' + str(row['date']) + '_ilmenau_deu_raw.csv'\n",
    "    # result_path =  '../data-raw/Ilmenau AUT/' + str(row['date']) + '_ilmenau_aut_raw.csv'\n",
    "    # result_path =  '../data-raw/Ilmenau CHE/' + str(row['date']) + '_ilmenau_che_raw.csv'\n",
    "    # result_path =  '../data-raw/owid/' + str(row['date']) + '_owid_raw.csv'\n",
    "    # result_path =  '../data-raw/globalrt/' + str(row['date']) + '_globalrt_raw.csv'\n",
    "    # result_path = '../data-raw/epiforecast_au_ch_ger/' + str(row['date']) + '_epiforecast_raw.csv'\n",
    "    result_path = '../data-raw/zidatalab/' + str(row['date']) + '_zidatalab_raw.json'\n",
    "    # result_path = '../data-raw/rki-historic/' + str(row['date']) + 'rki_historic_raw.csv'\n",
    "    # for owid only: filter only data from Germany:\n",
    "    # df_temp = df_temp.loc[df_temp['iso_code'] == 'DEU']\n",
    "    # for globalrt only: filter only data from Germany, Austria and Switzerland:\n",
    "    # df_temp = df_temp.loc[(df_temp['Country/Region'] == 'Germany') | (df_temp['Country/Region'] == 'Austria') | (df_temp['Country/Region'] == 'Switzerland')]\n",
    "    # for epiforecast:\n",
    "    # df_temp = df_temp[(df_temp.iloc[:, 0] == 'Germany') | (df_temp.iloc[:, 0] == 'Austria') | (df_temp.iloc[:, 0] == 'Switzerland')]\n",
    "    df_temp.to_csv(result_path, index=False)\n",
    "    # for zidatalab only:\n",
    "    df_temp.to_json(result_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3209603dc16fa08139850b0fbcec5529b2035f6d8448c78a588ebbadffc6ff1e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "3209603dc16fa08139850b0fbcec5529b2035f6d8448c78a588ebbadffc6ff1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

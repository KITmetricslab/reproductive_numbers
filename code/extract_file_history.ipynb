{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "source": [
    "# Before running, you have to set the parameters at these numbers: 1, 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize progress bars\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a github access token to perform a large number of requests (rate limit)\n",
    "with open(\"config.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "token = cfg['access_token']\n",
    "headers = {'Authorization': 'token ' + token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, change comments where needed\n",
    "\n",
    "# for ETHZ:\n",
    "# repo_name = 'covid-19-Re/dailyRe-Data'\n",
    "# branch = 'master'\n",
    "# file_path = 'DEU-estimates.csv'\n",
    "\n",
    "# for TU Ilmenau:\n",
    "# repo_name = 'Stochastik-TU-Ilmenau/COVID-19'\n",
    "# branch = 'gh-pages'\n",
    "# file_path = 'data/estimates/Germany_RKI_R.csv'\n",
    "\n",
    "# for OWID:\n",
    "repo_name = 'owid/covid-19-data'\n",
    "branch = 'master'\n",
    "file_path = 'public/data/owid-covid-data.csv'\n",
    "# Note that OWID reports reproduction_rate only since 2020-11-13, this script will also download older data. This older data has to be removed from the data-raw folder before running the \"process_historic_data_owid.r\" script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get commit history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve information about all commits that modified the file we want\n",
    "all_commits = []\n",
    "\n",
    "page = 0\n",
    "while True:\n",
    "    page += 1\n",
    "    r = requests.get('https://api.github.com/repos/{}/commits'.format(repo_name),\n",
    "                     params = {'sha': branch, 'path': file_path, 'page': str(page)},\n",
    "                     headers=headers)\n",
    "\n",
    "    if (not r.ok) or (r.text == '[]'): break\n",
    "\n",
    "    all_commits += json.loads(r.text or r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sha of each commit\n",
    "all_shas = [c['sha'] for c in all_commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of each commit\n",
    "commit_dates = [pd.to_datetime(c['commit']['author']['date']) for c in all_commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframe\n",
    "df = pd.DataFrame({'sha': all_shas, 'commit_date': commit_dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date without time\n",
    "df['date'] = df.commit_date.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider last commit made each day\n",
    "df = df.loc[df.groupby('date')['commit_date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           sha               commit_date  \\\n",
       "1722  697cc89c03de8622d50c50074edeb842e35ba33c 2020-04-16 20:24:09+00:00   \n",
       "1719  a9355803a303312ea889d31f5b3c5a8f95fee267 2020-04-17 17:15:09+00:00   \n",
       "1717  348f83eeff6acc5fc58a3b55e08398c096bc22bf 2020-04-18 17:15:12+00:00   \n",
       "1715  9ee33ac73942b2e37eb04014bf2a7a17a83998cf 2020-04-19 14:37:16+00:00   \n",
       "1713  8222d828a8af35147af3a9ad983a424f22d2037b 2020-04-20 21:30:07+00:00   \n",
       "\n",
       "            date  \n",
       "1722  2020-04-16  \n",
       "1719  2020-04-17  \n",
       "1717  2020-04-18  \n",
       "1715  2020-04-19  \n",
       "1713  2020-04-20  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sha</th>\n      <th>commit_date</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1722</th>\n      <td>697cc89c03de8622d50c50074edeb842e35ba33c</td>\n      <td>2020-04-16 20:24:09+00:00</td>\n      <td>2020-04-16</td>\n    </tr>\n    <tr>\n      <th>1719</th>\n      <td>a9355803a303312ea889d31f5b3c5a8f95fee267</td>\n      <td>2020-04-17 17:15:09+00:00</td>\n      <td>2020-04-17</td>\n    </tr>\n    <tr>\n      <th>1717</th>\n      <td>348f83eeff6acc5fc58a3b55e08398c096bc22bf</td>\n      <td>2020-04-18 17:15:12+00:00</td>\n      <td>2020-04-18</td>\n    </tr>\n    <tr>\n      <th>1715</th>\n      <td>9ee33ac73942b2e37eb04014bf2a7a17a83998cf</td>\n      <td>2020-04-19 14:37:16+00:00</td>\n      <td>2020-04-19</td>\n    </tr>\n    <tr>\n      <th>1713</th>\n      <td>8222d828a8af35147af3a9ad983a424f22d2037b</td>\n      <td>2020-04-20 21:30:07+00:00</td>\n      <td>2020-04-20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 454/454 [20:04<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# iterate over the rows of df and download the corresponding file\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):        \n",
    "    df_temp = pd.read_csv('https://raw.githubusercontent.com/{}/{}/{}'.format(repo_name, row['sha'], file_path),\n",
    "                          low_memory=False)\n",
    "#2\n",
    "    # result_path =  '../data-raw/ETH Zürich/' + str(row['date']) + '_zürich_raw.csv'\n",
    "    # result_path =  '../data-raw/TU Ilmenau/' + str(row['date']) + '_Ilmenau_raw.csv'\n",
    "    result_path =  '../data-raw/owid/' + str(row['date']) + '_owid_raw.csv'\n",
    "    # for owid only: filter only data from Germany:\n",
    "    df_temp = df_temp.loc[df_temp['iso_code'] == 'DEU']\n",
    "    #\n",
    "    df_temp.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "3209603dc16fa08139850b0fbcec5529b2035f6d8448c78a588ebbadffc6ff1e"
   }
  },
  "interpreter": {
   "hash": "3209603dc16fa08139850b0fbcec5529b2035f6d8448c78a588ebbadffc6ff1e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}